name: 每日自动采集环保政策

on:
  schedule:
    - cron: '0 0 * * *'  # 每天UTC 0点（北京时间8点）
  workflow_dispatch:  # 允许手动触发

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
    # 1. 检出代码
    - name: Checkout
      uses: actions/checkout@v4
      
    # 2. 设置Node.js环境（构建React需要）
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        
    # 3. 设置Python环境（运行爬虫）
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        
    # 4. 安装Python依赖
    - name: Install Python dependencies
      run: |
        pip install requests beautifulsoup4
        
    # 5. 运行爬虫（生成 data.json）
    - name: Run scraper
      run: |
        mkdir -p public
        python scraper.py
        
    # 6. 安装Node依赖
    - name: Install Node dependencies
      run: npm install
      
    # 7. 构建React项目
    - name: Build project
      run: npm run build
      
    # 8. 部署到GitHub Pages
    - name: Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./dist  # React构建后的输出目录（可能是dist或build）
